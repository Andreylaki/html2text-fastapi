from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from bs4 import BeautifulSoup, Comment
from typing import Optional
import re
import html as htmlmod

# üëâ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç readability (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫ ‚Äî —Å–µ—Ä–≤–∏—Å –≤—Å—ë —Ä–∞–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
try:
    from readability import Document as ReadabilityDocument
except Exception:
    ReadabilityDocument = None

app = FastAPI(title="HTML‚ÜíText API")

# –†–∞–∑—Ä–µ—à–∏–º CORS –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (—É–¥–æ–±–Ω–æ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–æ–≤ –∏ –≤–Ω–µ—à–Ω–∏—Ö –≤—ã–∑–æ–≤–æ–≤)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class ExtractRequest(BaseModel):
    html: str
    url: Optional[str] = None
    use_readability: Optional[bool] = True  # –µ—Å–ª–∏ True –∏ –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å "–æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç"

class ExtractResponse(BaseModel):
    text: str
    title: Optional[str] = None
    source_url: Optional[str] = None
    length: int

def _normalize_text(text: str) -> str:
    """–ß–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤/–º—É—Å–æ—Ä–∞, —É–¥–∞–ª–µ–Ω–∏–µ cookie-—Å—Ç—Ä–æ–∫ –∏ –ø—Ä."""
    text = htmlmod.unescape(text or "")
    lines_out = []

    for raw in (text.splitlines() if text else []):
        line = re.sub(r"\s+", " ", raw).strip()
        if not line:
            continue

        # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±—É–∫–≤/—Ü–∏—Ñ—Ä ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ –º—É—Å–æ—Ä (cookie, JS-–æ–±—Ä—ã–≤–∫–∏ –∏ —Ç.–ø.)
        letters = len(re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë0-9]", line))
        punct = len(re.findall(r"[^A-Za-z–ê-–Ø–∞-—è–Å—ë0-9\s]", line))
        if letters == 0 or (letters and punct / (letters + punct) > 0.6):
            continue

        # –Ø–≤–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è cookie/GDPR/–±–∞–Ω–Ω–µ—Ä–æ–≤
        if re.match(r"^(cookie|cookies|gdpr|privacy|–ø–æ–ª–∏—Ç–∏–∫–∞|—Å–æ–≥–ª–∞—Å–∏–µ|–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)\b", line, flags=re.I):
            continue

        lines_out.append(line)

    text = "\n".join(lines_out)
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    return text

def _strip_tags_keep_text(html: str) -> str:
    """–£–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Ç–µ–≥–∏/–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ —Å—Ç—Ä–æ–∫."""
    soup = BeautifulSoup(html or "", "lxml")

    # –Ø–≤–Ω–æ –≤—ã–∫–∏–¥—ã–≤–∞–µ–º ¬´—Ç—è–∂—ë–ª—ã–µ¬ª –∏–ª–∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
    for sel in [
        "script","style","noscript","svg","canvas","template","iframe",
        "form","input","button","nav","footer","header","aside","menu",
        "figure","picture","video","audio","source"
    ]:
        for t in soup.select(sel):
            t.decompose()

    # —á–∞—Å—Ç—ã–µ –∫–ª–∞—Å—Å—ã/–∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –±–∞–Ω–Ω–µ—Ä–æ–≤, –º–æ–¥–∞–ª–æ–∫, cookie, —Ä–µ–∫–ª–∞–º—ã
    for sel in [
        '[role="dialog"]','[aria-hidden="true"]','[hidden]',
        '.cookie','#cookie','#cookies','.gdpr','.banner','.popup','.modal','.advert','.ads',
        '[class*="cookie"]','[id*="cookie"]','[class*="banner"]','[id*="banner"]',
        '[class*="advert"]','[id*="advert"]'
    ]:
        for t in soup.select(sel):
            t.decompose()

    # –£–¥–∞–ª—è–µ–º HTML-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    for c in soup.find_all(string=lambda x: isinstance(x, Comment)):
        c.extract()

    text = soup.get_text(separator="\n", strip=True)
    return _normalize_text(text)

@app.post("/extract", response_model=ExtractResponse)
def extract(req: ExtractRequest):
    raw = req.html or ""
    title = None

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º readability —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –æ—Ç–∫–ª—é—á–∏–ª + –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω
    use_readability = bool(req.use_readability and ReadabilityDocument is not None)

    if use_readability:
        try:
            doc = ReadabilityDocument(raw)
            title = (doc.short_title() or "").strip() or None
            main_html = doc.summary(html_partial=True)
            text = _strip_tags_keep_text(main_html)
        except Exception:
            text = _strip_tags_keep_text(raw)
    else:
        text = _strip_tags_keep_text(raw)

    if not title:
        try:
            soup = BeautifulSoup(raw, "lxml")
            if soup.title and soup.title.string:
                title = soup.title.string.strip()
        except Exception:
            pass

    return ExtractResponse(text=text, title=title, source_url=req.url, length=len(text))

@app.get("/")
def health():
    return {"ok": True}

# –ª–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ (–Ω–µ –Ω—É–∂–µ–Ω –≤ Docker/–Ω–∞ Railway, –æ—Å—Ç–∞–≤–ª–µ–Ω –Ω–∞ –≤—Å—è–∫–∏–π)
if __name__ == "__main__":
    import uvicorn
    import os
    port = int(os.environ.get("PORT", "8000"))
    uvicorn.run("app:app", host="0.0.0.0", port=port, reload=False)
